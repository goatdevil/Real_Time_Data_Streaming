{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjbt34Pr1Hks"
      },
      "source": [
        "\n",
        "<font color=\"green\"> <h1 align=\"center\"> ESME - Big Data & Digital Marketing </h1>  </font>  \n",
        "\n",
        "\n",
        "<font color=\"green\"> <h2 align=\"center\"> Révision </h2> </font>\n",
        "\n",
        "\n",
        "<font color=\"green\"> <h3 align=\"center\"> NASSE ABALORI MARTIN </h3></font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=\"green\"> <h3 align=\"left\">IV. Utilisation de Kafka en Python</h3></font>\n",
        "<table>\n",
        "<thead>\n",
        "<tr>\n",
        "<th>Opération</th>\n",
        "<th>Description</th>\n",
        "<th>Exemple</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr>\n",
        "<td><b>Importation des modules Kafka</b></td>\n",
        "<td>Importation des modules nécessaires pour travailler avec Kafka en Python.</td>\n",
        "<td><code>from kafka import KafkaProducer, KafkaConsumer</code><br><code>from kafka.admin import KafkaAdminClient, NewTopic</code></td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>Création d'un Topic Kafka</b></td>\n",
        "<td>Créer un nouveau topic dans Kafka.</td>\n",
        "<td>\n",
        "<pre>\n",
        "admin_client = KafkaAdminClient(bootstrap_servers='localhost:9092', client_id='test')<br>\n",
        "topic_list = [NewTopic(name=\"mon_topic\", num_partitions=1, replication_factor=1)]<br>\n",
        "admin_client.create_topics(new_topics=topic_list, validate_only=False)\n",
        "</pre>\n",
        "</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>Création d'un Producer</b></td>\n",
        "<td>Envoyer des messages au topic Kafka.</td>\n",
        "<td>\n",
        "<pre>\n",
        "producer = KafkaProducer(bootstrap_servers='localhost:9092')<br>\n",
        "producer.send('mon_topic', b'Message Test')\n",
        "</pre>\n",
        "</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>Création d'un Consumer</b></td>\n",
        "<td>Lire des messages depuis le topic Kafka.</td>\n",
        "<td>\n",
        "<pre>\n",
        "consumer = KafkaConsumer('mon_topic', bootstrap_servers='localhost:9092')<br>\n",
        "for message in consumer:<br>\n",
        "&nbsp;&nbsp;&nbsp;print(message.value)\n",
        "</pre>\n",
        "</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><b>Gestion des erreurs Kafka</b></td>\n",
        "<td>Gérer les exceptions liées à Kafka.</td>\n",
        "<td>\n",
        "<pre>\n",
        "try:<br>\n",
        "&nbsp;&nbsp;&nbsp;# Opérations Kafka<br>\n",
        "except KafkaError as e:<br>\n",
        "&nbsp;&nbsp;&nbsp;print(f\"Erreur Kafka: {e}\")\n",
        "</pre>\n",
        "</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=\"green\"> <h3 align=\"left\">Exercice Pratique sur Kafka en Python</h3></font>\n",
        "<p><b>Contexte :</b> Vous travaillez sur un projet qui nécessite l'intégration de Kafka pour le traitement de données en temps réel. Votre objectif est de mettre en place un système simple de production et de consommation de messages avec Kafka.</p>\n",
        "\n",
        "<p><b>Exercices :</b></p>\n",
        "<ol>\n",
        "<li><b>Installation de Kafka-Python :</b>\n",
        "<ul>\n",
        "<li>Installez la bibliothèque kafka-python en utilisant pip.</li>\n",
        "</ul>\n",
        "</li>\n",
        "<li><b>Création d'un Topic Kafka :</b>\n",
        "<ul>\n",
        "<li>Utilisez KafkaAdminClient pour créer un topic nommé <code>mon_topic_test</code>.</li>\n",
        "</ul>\n",
        "</li>\n",
        "<li><b>Création d'un Producer :</b>\n",
        "<ul>\n",
        "<li>Écrivez un script Python pour envoyer des messages dans <code>mon_topic_test</code>. Les messages peuvent être des chaînes simples ou des données structurées.</li>\n",
        "</ul>\n",
        "</li>\n",
        "<li><b>Création d'un Consumer :</b>\n",
        "<ul>\n",
        "<li>Écrivez un script Python qui lit et affiche les messages de <code>mon_topic_test</code>.</li>\n",
        "</ul>\n",
        "</li>\n",
        "<li><b>Gestion des erreurs :</b>\n",
        "<ul>\n",
        "<li>Intégrez la gestion des exceptions dans vos scripts pour gérer les erreurs potentielles lors de la connexion à Kafka ou lors de l'envoi/réception de messages.</li>\n",
        "</ul>\n",
        "</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "TopicAlreadyExistsError",
          "evalue": "[Error 36] TopicAlreadyExistsError: Request 'CreateTopicsRequest_v3(create_topic_requests=[(topic='mon_topic_test', num_partitions=1, replication_factor=1, replica_assignment=[], configs=[])], timeout=30000, validate_only=False)' failed with response 'CreateTopicsResponse_v3(throttle_time_ms=0, topic_errors=[(topic='mon_topic_test', error_code=36, error_message=\"Topic 'mon_topic_test' already exists.\")])'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTopicAlreadyExistsError\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m admin_client \u001b[38;5;241m=\u001b[39m KafkaAdminClient(bootstrap_servers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost:9092\u001b[39m\u001b[38;5;124m'\u001b[39m, client_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m topic_list \u001b[38;5;241m=\u001b[39m [NewTopic(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmon_topic_test\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_partitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, replication_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m \u001b[43madmin_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m producer \u001b[38;5;241m=\u001b[39m KafkaProducer(bootstrap_servers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost:9092\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m consumer \u001b[38;5;241m=\u001b[39m KafkaConsumer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmon_topic_test\u001b[39m\u001b[38;5;124m'\u001b[39m, bootstrap_servers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost:9092\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/admin/client.py:461\u001b[0m, in \u001b[0;36mKafkaAdminClient.create_topics\u001b[0;34m(self, new_topics, timeout_ms, validate_only)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupport for CreateTopics v\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m has not yet been added to KafkaAdminClient.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(version))\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# TODO convert structs to a more pythonic interface\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# TODO raise exceptions if errors\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request_to_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/admin/client.py:407\u001b[0m, in \u001b[0;36mKafkaAdminClient._send_request_to_controller\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m error_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Errors\u001b[38;5;241m.\u001b[39mNoError:\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error_type(\n\u001b[1;32m    408\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed with response \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(request, response))\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[0;31mTopicAlreadyExistsError\u001b[0m: [Error 36] TopicAlreadyExistsError: Request 'CreateTopicsRequest_v3(create_topic_requests=[(topic='mon_topic_test', num_partitions=1, replication_factor=1, replica_assignment=[], configs=[])], timeout=30000, validate_only=False)' failed with response 'CreateTopicsResponse_v3(throttle_time_ms=0, topic_errors=[(topic='mon_topic_test', error_code=36, error_message=\"Topic 'mon_topic_test' already exists.\")])'."
          ]
        }
      ],
      "source": [
        "from kafka import KafkaProducer, KafkaConsumer\n",
        "from kafka.admin import KafkaAdminClient, NewTopic\n",
        "\n",
        "admin_client = KafkaAdminClient(bootstrap_servers='localhost:9092', client_id='test')\n",
        "topic_list = [NewTopic(name=\"mon_topic_test\", num_partitions=1, replication_factor=1)]\n",
        "admin_client.create_topics(new_topics=topic_list, validate_only=False)\n",
        "\n",
        "\n",
        "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
        "\n",
        "\n",
        "consumer = KafkaConsumer('mon_topic_test', bootstrap_servers='localhost:9092')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<kafka.producer.future.FutureRecordMetadata at 0x7fed5001e500>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "producer.send('mon_topic_test', b'ceci est un quatrieme message de test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'ceci est un quatrieme message de test'\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m consumer:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message\u001b[38;5;241m.\u001b[39mvalue)\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/consumer/group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/consumer/group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/consumer/group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1115\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m-> 1116\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[1;32m   1122\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/consumer/group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/consumer/group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    701\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 702\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    599\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    600\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    606\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/kafka/client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    633\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 634\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for message in consumer:\n",
        "    print(message.value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
